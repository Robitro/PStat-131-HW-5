---
title: "HW5"
output: html_document
date: "2022-11-16"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(tidymodels)
library(janitor)
library(ggplot2)
library(glmnet)
library(pROC)

```

###1
```{r}
poke_data <- read.csv("Pokemon.csv")

poke_data<-clean_names(poke_data)


```

The clean names function took the column names and turned them lowercase as well as turned periods into underscores.

###2
```{r}
pokebar <- ggplot(poke_data, aes(y=type_1)) + geom_bar()

pokebar

poke_data_f <-subset(poke_data,type_1 %in% c("Bug","Fire","Grass","Normal","Water","Psychic"))  

poke_data_f$type_1 <- as.factor(poke_data_f$type_1)  

poke_data_f$legendary <-as.factor(poke_data_f$legendary)
```
There are 18 types of Pokemon, the types are fairly evenly distributed, with the exception of flying type which has very few, fairy type does have a little less as well. 

###3
```{r}
set.seed(6688)
poke_data_split <- initial_split(poke_data_f, prop=.7, strata = type_1) 

poke_train <- training(poke_data_split)
poke_test <- testing(poke_data_split)

#318 training observations
count(poke_train)
# 140 testing observations
count(poke_test)

poke_folds <- vfold_cv(poke_train, v = 5, stata = type_1)

```
There are multiple categorical outcomes so it is important to stratify again to get accurate cross validation.

###4
```{r}
poke_re <- recipe(type_1 ~ legendary + generation+sp_atk+attack+speed+defense+hp+sp_def, data = poke_train) %>% step_dummy(c(legendary,generation)) %>% step_normalize(all_numeric_predictors())

 


```

###5

```{r}
mix_spec <- 
  multinom_reg(penalty = tune(), mixture = tune()) %>% 
  set_mode("classification") %>% 
  set_engine("glmnet")

poke_wf <- workflow( ) %>% add_recipe(poke_re) %>% add_model(mix_spec)
  
tune_grid <- grid_regular(penalty(c(-5,5)),mixture(c(0,1)),levels = 10)


```
We are fitting 10*10 grid to 5 folds so fitting 100 models.


###6
```{r eval=FALSE}
tune_res <- tune_grid(poke_wf, resamples = poke_folds, grid = tune_grid)
#save(tune_res, file = "tune_res.rda")

```

```{r}
load(file = "tune_res.rda")

autoplot(tune_res)
```

it appears that small values of penalty and large values of mixture produce the best results on accuracy and ROC curve.

###7
```{r}
best_tune <- select_best(tune_res,metric ='roc_auc')

poke_wf_final <- finalize_workflow(poke_wf,best_tune)

poke_final_fit <- fit(poke_wf_final, poke_train)

augment(poke_final_fit, poke_test) %>% accuracy(truth= type_1, estimate = .pred_class) 

```

Our multinomial regression model predicted Pokemon with 36.43% accuracy, if values were evenly randomly assigned, we would expect only 16.66% accuracy.

###8
```{r}
type_pred <- predict(poke_final_fit,poke_test)

poke_results <- bind_cols(poke_test,type_pred,id=NULL)

conf_mat(poke_results,truth = type_1, estimate = .pred_class) 


#multiclass.roc(poke_results$type_1,type_pred )

```